# Associating sampling priority with the trace

Enable consistent sampling across distributed application with different
sampling rates and probability calculation algorithms.

## TL;DR

**Priority** in the scope of this spec is a score associated with trace.
It's calculated when trace starts and flows in the `tracestate`, it's
used by samplers to make consistent sampling decisions.

Service that starts the trace calculates sampling priority and adds it to the
`tracestate` so downstream services can use it to make their sampling decisions
without re-calculating priority as a function of trace-id (or trace-flags).

## Motivation

The goal is to enable a mechanism for consistent (best effort) sampling
between services with different sampling rates and different probability
calculation algorithms (for interoperability with existing tracing tools).

Consistent sampling decision made in each app of a distributed trace is
important for better user experience of trace analysis. Consistency is achieved
by following means:

1. Same hashing algorithms used across all apps in a trace.
   Coordination of sampling algorithms across multiple apps not always possible:
   for example existing components in a system use vendor-specific
   tracing tool (pre-OpenTelemetry and update is hard to justify) while there
   is a desire to use OpenTelemetry for new components.

2. Sampling flag propagated from the head component/app is used by downstream
   apps to sample in a given trace.
   It requires to trust upstream decision and does not allow to have different
   sampling rates across different components.

## Explanation

Sampling propabaility is generated by the first service to make sampling
decision. It's a random float number in [0, 1] range.
Priority is stamped on the span and also propagated further within `tracestate`.

Next service reads priority from `tracestate` (instead of calculating it from
trace-id) and compares it with its sampling rate to make sampling decision.

Priority is also exposed through span attributes. Vendors can leverage it
to sort traces based on their completeness: the lower the value of priority is,
the higher the chance it was sampled it by each component.

### Example

```
+----------------------+     +----------------------+     +----------------------+
+ Service-A (rate 0.6) + --> + Service-B (rate 0.1) + --> + Service-C (rate 0.5) +
+-------------- -------+     +----------------------+     +----------------------+
```

1. Service-A receives a request
   - starts a new trace, generates random trace-id
   - generates priority: `0.17935003`. It's **smaller** than sampling rate
     (`0.6`), so decision is `RECORD_AND_SAMPLED`
   - span gets a new attribute `sampling.priority = 0.17935003`
   - tracestate is modified `sampling.priority=0.17935003`
2. Service-B gets request from A
   - reads trace-context from headers and `sampling.priority` from the
     tracestate
   - decision is `NOT_RECORD` as `0.17935003` is **bigger** than its
     sampling rate (0.1)
3. Service-C get a request from B
   - reads trace-context from headers and `sampling.priority` from the
     tracestate
   - decision is `RECORD_AND_SAMPLED` as `0.17935003` is **smaller** than its
     sampling rate (0.5)
   - span gets a new attribute `sampling.priority = 0.17935003`
   - tracestate is left untouched

As a result, spans from Service-A and Service-C are exported.
It's not possible to restore relationship between A and C without B and the
trace is broken, but Service-C can trace their own requests regardless of B's
sampling rate and B can have smaller tracing budget regardless of A's decisions.
All of them can still debug integration issues using common trace-id.

Vendors can pick the most complete traces sorting them by priority.

## Internal details

- Service that starts a trace makes sampling decision.  It's configured to use
`ExternalPrioritySampler`(name TBD) is configured by user. Within `ShouldSample`
callback sampler
  - generates random float priority (TBD precision) in [0, 1] interval
  - makes sampling decision by comparing generated priority to configured rate
  - if decision is `RECORD` (or `RECORD_AND_SAMPLED`), sampler adds
    `sampling.priority` attribute to attributes collection of to-be-created span
  - regardless of sampling decision: prepends `sampling.priority` key-value pair
    into tracestate of to-be-created span
- Downstream service continues a trace but has different sampling rate (it's
  also configured to use `ExternalPrioritySampler`)
  - `ExternalPrioritySampler.ShouldSample` checks if priority is provided in
    `tracestate`.
  - makes sampling decision by comparing upstream-generated priority with its
    sampling rate
  - if span will be recorded: sampler adds `sampling.priority` attribute to
    attributes collection of to-be-created span

Here is a [proof of concept](https://github.com/lmolkova/opentelemetry-dotnet/pull/1)
in .NET.

### Specification Delta

1. Add `SamplingResult.Tracestate` field: sampler should be able to assign a
   new tracestate for to-be-created span
2. Add convention for `sampling.priority` attribute on span
3. Add `ExternalPrioritySampler` implementation of `Sampler`

### Trade-offs and mitigations

This change would be the first (AFAIK) common use case of the `tracestate`.
It comes with bandwidth and performance overhead: `tracestate` could have
been just propagated [blindly](https://github.com/open-telemetry/opentelemetry-specification/issues/478).
and the overhead is made before sampling decision and cannot be mitigated.

Customers should configure it explicitly to avoid the overhead in the default
case when interoperability is not necessary.

Vendors may gradually update their existing solutions to support external
priority in order to interoperate with OpenTelemetry and should recommend
customers to configure such sampler.

It may be the case that after migration to OpenTelemetry is finalized, the need
of `sampling.priority` will decrease and customers can remove
`ExternalPrioritySampler` from configuration.

## Prior art and alternatives

[OpenTelemetry collector](https://github.com/open-telemetry/opentelemetry-collector/blob/60b03d0d2d503351501291b30836d2126487a741/processor/samplingprocessor/probabilisticsamplerprocessor/testdata/config.yaml#L10) uses `sampling.priority`
[OpenTracing](https://github.com/opentracing/specification/blob/master/semantic_conventions.md)
defined implementation-specific hint for sampler to prioritize recording a span.
Related discussions on [Probability sampler](https://github.com/open-telemetry/opentelemetry-specification/pull/570)

## Open questions

### Priority calculation: can we use ProbabilitySampler?

This spec suggests to generate priority randomly to achieve uniform
distribution.

Assuming trace-ids are uniformly distributed, `ProbabilitySampler` can generate
priority, so the flow could look like this:

`ExternalPrioritySampler.ShouldSample`:

- checks if `sampling.priority` is available in the tracestate
- if it's not there, invokes `ProbabilitySampler`, which calculates priority
  and populates it on the attributes
- updates tracestate

#### Pros

Fallback to `ProbabilitySampler` improves the case when `tracestate` is trimmed
so there is a chance sampling could be consistent if same probability
calculation algorithm was used.

#### Cons

- There is no requirement for trace-ids to be uniformly distributed
- No clear boundary between `ProbabilitySampler` and `ExternalPrioritySampler`.
`ProbabilitySampler` needs to set priority in attribute even if there is no
`ExternalPrioritySampler`.

## Future possibilities

### Attribute vs field on the span to-be-created

Collection of attributes which is passed to sampler is empty by default to
minimize perf impact. Propagating priority back from sampler to span requires
to initialize the collection.

Creating a new float field on `SamplingDecision` could be an alternative.
It'd also require adding similar property on Span/SpanData.
